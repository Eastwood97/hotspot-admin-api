server.port=9090

server.tomcat.max-http-post-size=-1

#spring.redis.host=127.0.0.1

#spring.redis.port=6379
#最大连接数
#spring.redis.jedis.pool.max-active=9
#最大阻塞等待时间(负数表示没限制)
#spring.redis.jedis.pool.max-wait=-1
#最大空闲
#spring.redis.jedis.pool.max-idle=8
#最小空闲
#spring.redis.jedis.pool.min-idle=0

#spring.redis.pool.timeout=3000


## 连接池最大连接数（使用负值表示没有限制）
#spring.redis.lettuce.pool.max-active=8
## 连接池最大阻塞等待时间（使用负值表示没有限制）
#spring.redis.lettuce.pool.max-wait=10000
## 连接池中的最大空闲连接
#spring.redis.lettuce.pool.max-idle=8
## 连接池中的最小空闲连接
#spring.redis.lettuce.pool.min-idle=0
## 关闭超时时间
#spring.redis.lettuce.shutdown-timeout=100

#spring.redis.timeout=10000

#spring.redis.database=0

#spring.redis.commandTimeout=5000

#spring.redis.cluster.nodes=127.0.0.1:6379

spring.redis.host=47.103.113.8

spring.redis.port=6379
#spring.redis.password=root #根据需要
# 连接超时时间（毫秒）
spring.redis.timeout=10000
# Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0
spring.redis.database=0
# 连接池最大连接数（使用负值表示没有限制） 默认 8
spring.redis.lettuce.pool.max-active=8
# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
spring.redis.lettuce.pool.max-wait=-1
# 连接池中的最大空闲连接 默认 8
spring.redis.lettuce.pool.max-idle=8
# 连接池中的最小空闲连接 默认 0
spring.redis.lettuce.pool.min-idle=0

spring.jackson.property-naming-strategy=LOWER_CAMEL_CASE
#server.address=192.168.56.11
#============== config ===================
spring.kafka.bootstrap-servers=47.103.113.8:9092

#=============== provider  =======================

spring.kafka.producer.retries=2
spring.kafka.producer.batch-size=16384
spring.kafka.producer.file.propertiesbuffer-memory=33554432

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
spring.kafka.consumer.group-id=pic-consumer-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#kafka.consumer.servers=hadoop101:9092,hadoop102:9092,hadoop103:9092
#kafka.consumer.enable.auto.commit=true
#kafka.consumer.session.timeout=20000
#kafka.consumer.auto.commit.interval=100
#kafka.consumer.auto.offset.reset=latest
#kafka.consumer.topic=result
#kafka.consumer.group.id=test
#kafka.consumer.concurrency=10
#
#kafka.producer.servers=hadoop101:9092,hadoop102:9092,hadoop103:9092
#kafka.producer.topic=result
#kafka.producer.retries=0
#kafka.producer.batch.size=4096
#kafka.producer.linger=1
#kafka.producer.buffer.memory=40960

tcp.port=9091
boss.thread.count=2
worker.thread.count=2
so.keepalive=true
so.backlog=100

camera1.ip=192.168.1.100
camera.port=8000
camera.username=admin
camera.password=Admin12345

